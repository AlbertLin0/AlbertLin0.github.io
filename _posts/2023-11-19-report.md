---
title: report
author: Haibo_Hu
date: 2023-11-04 11:33:00 +0800
categories: [Report]
tags: [读书笔记]
math: true
---

## 大模型的压缩能力

#### 1. **大模型的训练思维与压缩类似**
   
很多人相信压缩即智能。2月28日，OpenAI 的核心研发人员 Jack Rae 在参加 Stanford MLSys Seminar 的访谈时进行了一个名为 Compression for AGI 的主题分享，其核心观点为：AGI 基础模型的目标是实现对**有效信息最大限度的无损压缩。** 其主要思想如下：

##### 直观理解

![Alt text](/assets/img/image.png){: w="700" h="400" }

从查表学习，压缩后的数据能够得到本质的规律，比如苹果掉下来，可以联系到重力。OpenAI认为压缩可以通往通用人工智能。

#### 2. **训练方法与算术编码类似**

![Alt text](/assets/img/image-2.png)

其本质是找到最优的预测下一个token的概率分布，
![Alt text](/assets/img/image-1.png){: w="700" h="400" }

#### 3. **小实验证明其压缩能力**
引用自[Semantic Compression With Large Language Models](https://arxiv.org/abs/2304.12512)

![Alt text](/assets/img/image-3.png)

![Alt text](/assets/img/image-4.png)


语义相似性：

![Alt text](/assets/img/image-5.png)

#### 4. **缺点**

1. 压缩一切的思维很疯狂。
2. 对于大分辨率的图像来说，很难去压缩它，应该考虑传统的方法，比如压缩感知，即选择其有效的输入，降低图像的稀疏性。从概率的角度上讲，即降低图像的熵，让预测下一个像素的概率分布更平滑。
3. 很多数据观测不到，需要一些meta信息。


## 对于图像 

传统的jpeg压缩方式为，色彩空间-DCT-量化的过程。我通俗的理解为压缩低频信息，即压缩熵较低的部分。从语义的角度来讲，则是保留了与原图像一模一样的语义。

###### 信息相关
在绝大多数图像的像素之间，各像素之间，各像素行和帧之间存在着较强的的相关性。从统计观点出发，就是每个像素的灰度值（或颜色值），总是和其周围的其它像素的灰度值（或颜色值）存在某种关系，应用某种编码方法减少这些相关性就可实现图像压缩。

###### 信息冗余
从信息论的角度来看，压缩就是去掉信息中的冗余。即保留确定信息，去掉可推知的确定信息，用一种更接近信息本质的描述来代替原有的冗余描述。

当一幅图像的灰度级别直接用自然二进制编码来表示时，通常会存在冗余。大多数的图像数据存在着不同程度的编码冗余、像素之间的冗余和心理视觉冗余。

所谓像“素间的冗余”，是指单个像素携带的信息相对较少，单一像素对于一幅图像的多数视觉贡献是多余的，它的值可以通过与其相邻的像素的值来推断。

对于以改善视觉效果为目的的某些应用来说，用户通常允许图像有一定程度的失真；对于以特征提取和目标识别为目的的某些应用来说，用户通常关心的是那些边缘和轮廓信息，允许丢掉与其无关的信息。心里视觉冗余是指在正常的视觉处理过程中那些不十分重要的信息。心里视觉的产生是因为人类对图像信息的感知并不涉及对图像中每个像素值的定量分析。通常，观察者寻找可区别的特征，比如边缘或者文理区域，然后在心里将其合并成可识别的组群，最后，通过大脑将这些组群与先前已有的知识相联系以便完成图像的解释过程。